{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d241615",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Financial-Transactions\" data-toc-modified-id=\"Financial-Transactions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Financial Transactions</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Leaderboard-Predict-function\" data-toc-modified-id=\"The-Leaderboard-Predict-function-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>The Leaderboard Predict function</a></span></li><li><span><a href=\"#Testing-your-Implementation\" data-toc-modified-id=\"Testing-your-Implementation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Testing your Implementation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b18ca1",
   "metadata": {},
   "source": [
    "# Financial Transactions\n",
    "\n",
    "The ability to identify fraudulent transactions is of great interest to the payments industry. In this notebook, you will make use of the binary classifier you trained on the transcations dataset to detect fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a3ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bc300b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/mlproject22\" if os.path.exists(\"/data/mlproject22\") else \".\"\n",
    "train_data = pd.read_csv(os.path.join(path, \"transactions.csv.zip\"))\n",
    "X_train = train_data.drop(columns = \"Class\")\n",
    "y_train = train_data[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80383ed5",
   "metadata": {},
   "source": [
    "## The Leaderboard Predict function\n",
    "Replace the comment and `NotImplementedError` in the `leader_board_predict_fn` with code that loads your model parameters and returns the likelyhood of fraud for each transaction (i.e. row) in the values dataframe. Note that the returned array should contain a single decision function value for each transaction, indicating whether the transaction is fraudulent (i.e. it belongs to target class $1$). The higher the decision function value, the more likely that the transaction is fraud.\n",
    "You can import the packages you require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78ec27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leader_board_predict_fn(values):\n",
    "    \n",
    "    decision_function_values = np.zeros(values.shape[0])\n",
    "    \n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "\n",
    "    # load the trained model \n",
    "    filename = 'naive_bayes_model.sav'\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    # calculate the decision function value for reach row\n",
    "    decision_function_values = loaded_model.predict(values)\n",
    "\n",
    "    return decision_function_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e75b0",
   "metadata": {},
   "source": [
    "## Testing your Implementation\n",
    "Your model should return the probability or decision function value that indicates the likelyhood of fraud for each input transaction. To verify that this is the case, we run your model on a subset of the transactions dataset it was trained on. There is a hidden cell that performs the actual test on the unseen test set and computes your score for the leaderboard using the [ROC AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b1162eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Score: 0.8243203919170675\n",
      "Test Dataset Score: 0.7925770617757514\n"
     ]
    }
   ],
   "source": [
    "def get_score():\n",
    "    \"\"\"\n",
    "    Function to compute scores for train and test datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import pathlib\n",
    "\n",
    "    try:\n",
    "        path = \"/data/mlproject22\" if os.path.exists(\"/data/mlproject22\") else \".\"\n",
    "        test_data = pd.read_csv(os.path.join(path, \"transactions.csv.zip\"))\n",
    "        X_test = test_data.drop(columns = \"Class\")\n",
    "        y_test = test_data[\"Class\"]\n",
    "        decision_function_values = leader_board_predict_fn(X_test)\n",
    "        assert decision_function_values.shape == (X_test.shape[0],)\n",
    "        dataset_score = roc_auc_score(y_test, decision_function_values)\n",
    "        assert dataset_score >= 0.0 and dataset_score <= 1.0\n",
    "    except Exception:\n",
    "        dataset_score = float(\"nan\")\n",
    "    print(f\"Train Dataset Score: {dataset_score}\")\n",
    "\n",
    "    import os\n",
    "    import pwd\n",
    "    import time\n",
    "    import datetime\n",
    "    import pandas as pd\n",
    "    user_id = pwd.getpwuid( os.getuid() ).pw_name\n",
    "    curtime = time.time()\n",
    "    dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    try:\n",
    "        HIDDEN_DATASET_PATH = os.path.expanduser(\"/data/mlproject22-test-data\")\n",
    "        test_data = pd.read_csv(os.path.join(HIDDEN_DATASET_PATH,\"transactions_scoreboard.csv.zip\"))\n",
    "        X_test = test_data.drop(columns=[\"Class\"])\n",
    "        y_test = test_data[\"Class\"]\n",
    "        decision_function_values = leader_board_predict_fn(X_test)\n",
    "        hiddendataset_score = roc_auc_score(y_test, decision_function_values)\n",
    "        print(f\"Test Dataset Score: {hiddendataset_score}\")\n",
    "        score_dict = dict(\n",
    "            score_hidden=hiddendataset_score,\n",
    "            score_train=dataset_score,\n",
    "            unixtime=curtime,\n",
    "            user=user_id,\n",
    "            dt=dt_now,\n",
    "            comment=\"\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        err = str(e)\n",
    "        score_dict = dict(\n",
    "            score_hidden=float(\"nan\"),\n",
    "            score_train=dataset_score,\n",
    "            unixtime=curtime,\n",
    "            user=user_id,\n",
    "            dt=dt_now,\n",
    "            comment=err\n",
    "        )\n",
    "\n",
    "    #if list(pathlib.Path(os.getcwd()).parents)[0].name == 'source':\n",
    "    #    print(\"we are in the source directory... replacing values.\")\n",
    "    #    print(pd.DataFrame([score_dict]))\n",
    "    #    score_dict[\"score_hidden\"] = -1\n",
    "    #    score_dict[\"score_train\"] = -1\n",
    "    #    print(\"new values:\")\n",
    "    #    print(pd.DataFrame([score_dict]))\n",
    "\n",
    "    pd.DataFrame([score_dict]).to_csv(\"transactions.csv\", index=False)\n",
    "    \n",
    "get_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
